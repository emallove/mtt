Jeff's list of known bugs while trac is still being setup.  These will
shortly be added to trac and removed from here:

- test-get phase needs some kind of version number in the MTT meta
  data (just like mpi get) so that if the tests are updated and the
  MPI is not updated, we know to re-build/re-run the tests.

- need to properly handle the tests that are supposed to fail,
  particularly in the case where a set of tests is comprised of a
  bunch of tests that are supposed to pass and a few that are supposed
  to fail (E.g., the IBM and intel test suites).

- need to put in some kind of killall orted and whack session
  directories in the ompi core template.ini file.  Needs to be
  portable across linux, osx, and solaris (uck!).

- need to implement trim phase

- finish implementing hostlist / hostfile functionality (they're
  stored in globals; need to make them used in the .ini file and a
  funclet to pass the value in)

- add more usernames / passwords to server-side .htaccess so that
  we're not all using the same one

- have client pull down INI file from server and opt-out of certain
  configurations (i.e., enforce a common set of tests)

- ability for users to delete results (probably from PHP/server side,
  not in mtt client)

- save HTTP username with results

- *always* drops a pb_debug_.* file.


============================================================================

Notes from the first MTT developer's conference!

MTT Design goals:
 - Simple, easy to use INI file
 - Provide many hooks to provide support for everything, but not necessarily
   implementing the support directly.
 - MTT 1.0 file format may not be compatible MTT 2.0
 - For 1.0, focus on test suites the Open MPI group cares about
   - Correctness first, then performance, then other MPIs

============================================================================

Task list for 1.0/0.5:

Andrew Friedley
---------------

Finish up perfbase backend development
 - Finish perfbase xml output support
 - Look at organizing perfbase so that one run is a test suite, not one test
 - Finish email.pl to complete the perfbase reporting backend
Split reporter into formatting/data collection and transport
 - Transport - text, perfbase, psi, rsync, scp
 - Data collection - report mpi install, test build, test results


Jeff Squyres
------------

>>> DONE:
New syntax linkage between MPI and Test phases:
    [MPI Get: OMPI trunk]
    mpi_details=OMPI

    [MPI Get: OMPI branch]
    mpi_details=OMPI

    [MPI Install: optimized]
    mpi_get=OMPI trunk,OMPI branch

    [MPI Install: debug]
    mpi_get=OMPI trunk,OMPI branch

    [MPI Details: OMPI]

New "reverse" linkage between all phases

Implement "Trivial" plugins for "hello world" tests


>>> NOT DONE:

- add --dryrun option to show what *would* happen (probably should
  imply --verbose as well), but don't actually *do* anything (don't
  even alter any .xml internal state)

- finish fixing NPB build .pm to preoperly prefix all ini fieldnames
  and overall work properly

- SVN "get" method doesn't properly detect where there is nothing new

- fix up sample.ini to match new linkage and module field names

- add a --developer switch - run MTT against a current install

- audit output fields from MTT client for all phases so that they
  match the field names and types expected by the server

- make test results be output in a single output rather than reporting
  glumps of tests at a time

Active & Passive report mode - make reporting a phase?
 - Use cron for pushing reports through disconnected setups
   - Checking for new results to report every 10 mins
   - Gets daily before builds occur
   - Build daily on compile side, followed by a qsub to start compute nodes
   - Assume compile and compute nodes share filesystem

MTT global params:
 [MTT]
 name_delimiter=, # delimiter between names of references in name= field
 run_if_partial_build_fail=1 # run tests that DID build if test build fails

Finish implementing trim phase

Implement 'test specify' phase - replaces current test run INI stuff
 - Should generate a list of tuples, which is:
   - exec - binary to execute
   - argv
   - np
   - pass - success return code
   - timeout
   - before_any
   - before_each
   - after_each
   - after_all
 - Test run phase should then accept this list
 - INI file looks like this:
    [test specify: intel]
    test_build = intel
    module = intel

   [test_build: intel]
   test_get = intel
   module = intel
   intel_buildfile=coll


Jim Barker
----------

Disconnected scenarios - mpi/test get proxies
 - Support different protocols - via module?  need rsync, scp, ...
 - Stage parameters:
   - force
   - retry
   - timeout

Split reporter into formatting and transport
Support for these test suites:
 intel
 ibm - Brian will check all tests compile/run under make/make check
 imb
 npb
 netpipe
 mpich - Brian may set up an OMPI version
Support for 'tcl' modules via perl bindings


Someone needs to write a 'simple' test specify module:
 module = simple
 simple_np = ...
 simple_exec = ...
 simple_argv = ...
 simple_pass = ...
 simple_timeout = ...

behavior should be combinatorial for the np, exec, and argv, if some sort of
lists are provided all combinations should be generated. pass and timeout are
considered constant, and should only have one value.

============================================================================

Features NOT to worry about for 1.0:

 - Expand stages beyond test build - specify - run
 - Support for gromacs and other complicated output
 - Expanded disconnected support
 - Less reliance on user to develop cron jobs and such
 - Support more test suites, MPIs
   - HPL
- Finer grained control when forcing stages to rerun - rather than rerunning a
  whole stage, let's select which INI section we want to rerun





- A lot of the parameters / report fields in the MPI install phase
  seem to assume that the MPI is built from source.  This assumption
  should be removed, and only report such fields from MPI install
  modules that need them.

- In the email script running behind perfbase:
  - Summarize how many installs/builds/runs failed
  - Give a different subject if anything failed

- From code review:
  - make the version number that perfbase.php checks be the same
    version number that the client uses to send -- e.g., check it in a
    file somewhere
  - brian's point about fork/exec in php code -- perhaps we should use
    apache as a proxy to a standalone process that is not running as
    apache.  two issues:
    - helps performance, because we don't fork/exec
    - don't run as apache, so that if our php or perfbase has a bug,
      that user will have limited
  - other things can print to php/stderr:
    - getcwd()
    - fclose()
    - putenv()
    - proc_open() (?)
    --> should we turn off all error reporting (based on a config
        variable)?
  - MTT_DEBUG should be ditched -- change to $debug

- The way we do the Intel tests for the tests that aren't supposed to
  pass isn't so great right now -- we have to have a section INI file
  section with a different "pass" rule.  It would be nice to be able
  to handle all the Intel tests in a single section -- the question
  is: how?  We talked about a few options, but it always got
  complicated -- either in the .ini file and/or in the
  implementation.  Here's some of the options we talked about:

  1. one global expression, and individual overrides

     pass = some_general_expression
     MPI_Abort_c_pass = some_other_expression
     MPI_Abort_f_pass = some_other_expression
     ...

     This is the Automake-ish way, but isn't super-scalable (i.e., we
     have to explcitily list each test that is different).

  2. give pass a list of tuples -- paring test names with expressions
     to check for success, something like:

     pass = &enumerate( \
       &tuple(&remove(&tests, @nonzero_tests@), ..check for 0...) \
       &tuple(@nonzero_tests@, ..check for non-0...) \
     )

     This, unfortunately, has some problems:
     - &tuple() could be implemented, but it is effectively a new
       datatype and may require some thought
     - see the discussion below about &remove() and lists in general
     - the current parsing engine expands from inside-out.  So the
       above expression would evaluate the "...check for 0..." during
       the initial expansion.  It would not result in a list of
       tuples, where the second element of the tuple is an expression
       that can be evaluated later.  Possible solution for this is to put
       the "...check for 0..." expression in a string, but that feels
       kinda icky...?

- It would be nice to be able to have a &remove() function that would
  take one list and remove elements from it, e.g.:

    &remove(&some_big_list(), "foo", "bar", "baz")

  But right now, this will first expand &some_big_list() and therefore
  make N instances of &remove().  It would still give the Right
  answer, but be horribly inefficient (i.e., if "foo" appears in
  &some_big_list(), then one of the instances will be "&remove("foo",
  "foo", "bar", "baz")" and its return will be empty -- so the union
  of answers from all the &remove instances will not have "foo" in
  it).  Even worse:

    &remove(&some_big_list(), &enumerate("foo", "bar", "baz"))

  Will make the combinatorial of N and 3 instances of &remove(), which
  will definitely result in the wrong answer (because we'll have 3
  copies of every item from &some_big_list() that is not "foo", "bar",
  or "baz" -- and two copies of "foo", etc.)

  It would seem like we should be able to pass lists around -- not do
  the default expansion and just be able to pass an explicit list.
  Perhaps we should explore using "@" in the syntax...?
  (hypothetically still allowing a perl "eval"...?)

- Rainer mentioned that we're requiring a bunch of Perl modules that
  aren't necessarily installed by default on some older machines
  (e.g., his).  He installed them to make it work, but it might be
  nice if we can cut down on the number of requirements --
  particularly when running on MTT on parallel compute nodes, where
  perl installs are likely to be minimal (i.e,. all we need to do is
  run thests and dump output to files there; no need for fancy
  downloading perl modules, etc.).  From a mail from Rainer:

    it seems that quite a few packets are required to build the 
    ParallelUserAgent-2.56
    libwww-perl-5.803   /* which is considered to be too new */
      -> depends on Compress-Zlib-2.000_05
    URI-1.35
    HTML-Parser
      -> depends on HTML-Tagset-3.10

- Ideas from working with Rainer in Houston:
  - Allow use of environment variables in the INI - an &env() function?
  - Add &split()
  - Allow for compiling the MPI with one compiler, but compiling the
    test suites with another compiler.  I believe we can do this
    already, by using &shell() for the test suite build and linking by
    hand.  If anything, we need a way of gettting good path
    information to do it.
  - Support for other schedulers
    - More specifically, killing off jobs.  If we qsub to do an mpirun, how do
      we kill it?
  - IF any failures occure, have MTT generate an INI file which can then be
    fed back into MTT, and only reproduce the work leading to the failures.
  - Optimize vpath - have multiple builds off of one source tree

- Add an option to have MTT only report results, and do nothing else.

- Finish Test/Build/NPB.pm, Test/Run/NPB.pm

- Should we save the output of the test build module (i.e., the list
  of tests) and use that (by default) in the test run module?
  - Build has capability to filter (e.g., Intel filters based on what
    bindings exist), but run/simple does not.  So you can not build
    the fortran tests, but then still try to run them of "tests =
    src/&cat(file)" -- how can we get the filtering down there
    (easily)?

- Add better error checking to perfbase.php
  - can we check to ensure that we're not inputting a duplicate result
    into perfbase?  what happens if we input a duplicate result into
    perfbase? 
    - Perfbase reports an error if duplicate data is given.  Make sure the
      client handles the error correctly.

- add support for some performance-oriented tests

- add support for disconnected scenarios

- do perfbase http put better; can all the queued http put's be
  combined into a single put? (i.e., make server side php smarter?)

- be able to handle case where svn checkouts go badly and svn
  ends up waiting for input (E.g., username or password).  Should be
  able to detect this somehow and know to kill it.

- add pre_hook and post_hook to all sub modules that run before the
  main action and after the main action; intent is to [optionally]
  give some arguments sufficient to launch another engine.pl in the
  next phase (e.g., have a post_hook to BuildMPI that runs engline.pl
  in the BuildTests phase).

- make centralized database download set of constants for the db
  (e.g., how many lines of stderr to report, etc.)

- need a lockfile to protect all the XML files in case multiple
  engines running simultaneously

- add trimming functionality: deleting old builds
    - put real timestamps in saved xml; delete trees older than a
      given date?
